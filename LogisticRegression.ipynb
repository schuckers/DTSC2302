{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Introduction\n",
    "\n",
    "Logistic regression is a statistical method used for binary classification tasks, where the goal is to predict a categorical outcome that has two classes (e.g., \"yes\" or \"no\", \"spam\" or \"not spam\"). Unlike linear regression, which predicts continuous values, logistic regression predicts the probability of a given input belonging to a certain class.\n",
    "\n",
    "The output of logistic regression is constrained to be between 0 and 1, representing the probability that an observation belongs to a particular class.\n",
    "\n",
    "\n",
    "This function maps any input value to a range between 0 and 1. It is used in logistic regression to convert the output of a linear equation into probabilities.\n",
    "\n",
    "We will use the famous **Iris Dataset** to classify whether a flower belongs to a specific species (Setosa or not).\n",
    "\n",
    "Let's begin by loading the necessary libraries and the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import statsmodels.api as sm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to start with some data on irises, the plant.  This data set has four different features/predictors all of which are measurements on the flower of an iris in centimeters.\n",
    "These measurement in order are: _sepal length_, _sepal width_, \t_petal length_ and _petal width_.\n",
    "\n",
    "The data also has species data and there are three species: _Iris Setosa_, _Iris Versicolour_, or _Iris Virginica_ and they are coded as 0, 1, and 2, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "print(iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define two functions, logit(p) which takes a probability and returns the log odds, and ilogit which takes log odds and returns a probability.  The latter is the inverse of the former."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def logit(p):\n",
    "    \"\"\"\n",
    "    Calculates the logit of a probability p.\n",
    "\n",
    "    Args:\n",
    "        p (float or numpy.ndarray): Probability value(s) between 0 and 1.\n",
    "\n",
    "    Returns:\n",
    "        float or numpy.ndarray: Logit value(s).\n",
    "    \"\"\"\n",
    "    p = np.asarray(p)\n",
    "    return np.log(p / (1 - p))\n",
    "\n",
    "def  ilogit(logodds):\n",
    "    ''' \n",
    "    Calculate the inverse logit or inverse log odds of a value.\n",
    "\n",
    "    Args:\n",
    "         float or numpy.ndarray: probability value(s).\n",
    "    '''\n",
    "    logodds = np.asarray(logodds)\n",
    "    return np.exp(logodds)/(1+np.exp(logodds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here are some sample values from these two functions.\n",
    "print(logit(0.4))\n",
    "print(logit(0.8))\n",
    "print(ilogit(0))\n",
    "print(ilogit(-2))\n",
    "print(ilogit(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we load in the iris data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "# we will start with just the sepal length\n",
    "X = iris.data[:,0]\n",
    "print(X)\n",
    "y = iris.target\n",
    "\n",
    "# For simplicity, let's classify whether the flower is of the species 'Setosa' or not.\n",
    "# \n",
    "y = (y == 0).astype(int)  # 1 if Setosa, 0 otherwise\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now, let's create a logistic regression model trying to predict our target, _y_, using the\n",
    "_sepal length_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.mean())\n",
    "# let's center X by subtracting the mean from each value.\n",
    "X = X - X.mean()\n",
    "\n",
    "# for this particular model formulation we need to add a \n",
    "# column of 1's to the feature array\n",
    "#add constant to predictor variables\n",
    "\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit logistic regression model using statsmodels\n",
    "model_sm = sm.Logit(y, X).fit()\n",
    "\n",
    "# Print the summary table, which includes p-values\n",
    "print(model_sm.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's intepret these coefficients.  For a logistic regression, the intepretations are similar but the response is the log-odds of the event, in this case the log odds of being an 'iris setosa'.\n",
    "\n",
    "So the '-2.41' is the predicted log odds of an iris that has a mean sepal length (of 5.84 cm) will be of the species 'setosa'.  \n",
    "\n",
    "For each additional cm of length, the predicted log odds of an iris being of the 'setosa' species decreases by -5.18.\n",
    "\n",
    "\n",
    "Next we find the predicted predicted probability of being a 'setosa' for the mean sepal length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a log-odds of -2.41, find the probability\n",
    "ilogit(-2.41)\n",
    "# here that is 0.0824."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's get the predicted probabilities for all of the data.  \n",
    "\n",
    "By default when we use the predict function for our model we get probabilities.  Some other versions of\n",
    "logistic regression (in different python packages) give you predicted log odds, others give you probabilities and others give you the predicted category (here 0 or 1) as your output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predicted probabilities of being a 1 \n",
    "# which here represents being an 'iris setosa'\n",
    "pred_probs=np.round(model_sm.predict(X),3)\n",
    "print(pred_probs)\n",
    "\n",
    "# convert probabilities to ones and zeros\n",
    "pred_cat = (pred_probs>0.5).astype(int)\n",
    "print(pred_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll look at a new dataset about whether or not students overdraw (take too much out of their bank account)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the monkey data\n",
    "overdrawn = pd.read_csv(\"https://webpages.charlotte.edu/mschuck1/classes/DTSC2302/Overdrawn.csv\")\n",
    "# get info about these data\n",
    "overdrawn.dropna(inplace=True)\n",
    "overdrawn.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is about students.  Here are the details on the variables in these data:\n",
    "\n",
    "_Age_ =\tAge of the student (in years)\n",
    "\n",
    "_Sex_ =\t0=male or 1=female\n",
    "\n",
    "_DaysDrink_ = Number of days drinking alcohol (in past 30 days)\n",
    "\n",
    "_Overdrawn_\t= Has student overdrawn a checking account? 0=no or 1=yes\n",
    "\n",
    "The first regression that we will do will use _DaysDrink_ as a predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overdrawn_X = overdrawn[['DaysDrink']]\n",
    "overdrawn_X = sm.add_constant(overdrawn_X)\n",
    "\n",
    "overdrawn_y = overdrawn['Overdrawn']\n",
    "print(overdrawn_X)\n",
    "model2_sm = sm.Logit(overdrawn_y, overdrawn_X).fit()\n",
    "\n",
    "# Print the summary table, which includes p-values\n",
    "print(model2_sm.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a similar summary to what we had previously for linear regression.  And we have coefficients to interpret.\n",
    "\n",
    "So for a student who had zero drinks in the last 30 days, we would expect that the log odds that they would be overdrawn to be -2.33.\n",
    "\n",
    "For each additional day that a student drank in the last 30 days, we would predict that the log odds of being overdrawn increase by 0.0541.\n",
    "\n",
    "Why might we not want to center the data here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "overdrawn_X = overdrawn[['Sex','Age']]\n",
    "overdrawn_X = sm.add_constant(overdrawn_X)\n",
    "\n",
    "overdrawn_y = overdrawn['Overdrawn']\n",
    "print(overdrawn_X)\n",
    "model2_sm = sm.Logit(overdrawn_y, overdrawn_X).fit()\n",
    "\n",
    "# Print the summary table, which includes p-values\n",
    "print(model2_sm.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's interpret these coefficients.  \n",
    "\n",
    "First our intercept, -7.05, is the predicted log odds of an age zero male being overdrawn.\n",
    "\n",
    "Next, the coefficient for _Sex_ is 0.9671 which means that a female will have a predicted log odds of being overdrawn that is 0.97 higher than a male with the same age.\n",
    "\n",
    "For each additional year of age, we expect that the log odds of being overdrawn will be predicted to increase by 0.23 assuming that _Sex_ remains the same.\n",
    "\n",
    "Below we center age so that our intercept coefficient is more interpretable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(overdrawn['Age'].mean())\n",
    "overdrawn['Age']=overdrawn['Age']-overdrawn['Age'].mean()\n",
    "overdrawn_X = overdrawn[['Sex','Age']]\n",
    "overdrawn_X = sm.add_constant(overdrawn_X)\n",
    "overdrawn_y = overdrawn['Overdrawn']\n",
    "print(overdrawn_X)\n",
    "model2_sm = sm.Logit(overdrawn_y, overdrawn_X).fit()\n",
    "\n",
    "# Print the summary table, which includes p-values\n",
    "print(model2_sm.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that after centering _Age_ the coefficients for _Sex_ and _Age_ remain the same, but the coefficient for _const_ changes.  \n",
    "\n",
    "From the above code, we can see that the average age of students in these data was 19.6 years of age.  Having subtracted that from _Age_, we now intepret the y-intercept as the predicted log odds that\n",
    "a 19.6 year old male would overdraw from their bank account is -2.56.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks\n",
    "\n",
    "1. Using the overdrawn data, fit a model that has _Age_, _Sex_ and as an interaction term between 'Age' and 'Sex'.  Interpret all of the coefficients.  \n",
    "\n",
    "2. Again with the overdrawn data, fit a model with all of the predictors including the interaction term from the previous task.  Which of the predictors is discernibly different from zero.\n",
    "\n",
    "3. Using the model from Task 2, remove any non-discernibly different from zero predictors from the model and get the predicted probabilities of being overdrawn.  \n",
    "\n",
    "4. Convert the predicted probabilities in the previous task to whether or not a student was overdrawn.  Is the predicted number of overdrawn students the same as the actual number of overdrawn students?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
