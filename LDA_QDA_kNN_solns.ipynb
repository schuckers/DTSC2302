{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification with LDA, QDA and kNN\n",
    "\n",
    "In this notebook we will look at implementing LDA, QDA and kNN models.\n",
    "\n",
    "We start with trying these approaches on data concerning breast cancer tumors.  With that data, we are trying to \n",
    "determine if a cancer cell is (M)alignant or (B)enign.  Malignant tumors are cancerous; benign tumors are harmless.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "import seaborn as sns\n",
    "\n",
    "# Setting plot style\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the bcancer data\n",
    "bcancer = pd.read_csv(\"https://webpages.charlotte.edu/mschuck1/classes/DTSC2301/Data/BreastCancer.csv\", na_values=['NA'])\n",
    "bcancer.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We are going to start with _Concavity_ and _Texture_ as predictors in our models.  We use two predictors/features primarily because we want to visualize the data which is harder to do once you get to more than two predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=bcancer[['Concavity','Texture']]\n",
    "y=bcancer['Diagnosis']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll look at a scatterplot of these data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note the alpha parameter here is for opacity or transparency\n",
    "# lower values for alpha make the points more transparent\n",
    "# so you can see the points behind a given point\n",
    "sns.scatterplot(data=bcancer, x='Concavity', y='Texture', hue='Diagnosis',alpha=0.6)\n",
    "# Set plot labels and title\n",
    "plt.title('Bivariate Plot Colored by Diagnosis')\n",
    "plt.xlabel('Concavity')\n",
    "plt.ylabel('Texture')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to scale the predictors here in the next cell of code.  The reason that we do this is that \n",
    "the kNN methodology depends upon distances since we are getting _nearest_ neighbors.  However, if the\n",
    "variables on are different scales, ie. have different variability, then the observations that are _nearest_\n",
    "might be defined simply based upon the feature that has the largest variation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA\n",
    "We will start with LDA.  \n",
    "\n",
    "Recall that, strictly speaking, the conditions for LDA are not met since we don't have\n",
    "Normality, nor do we have similar variances/covariances in both values for _Diagnosis_.\n",
    "Note that in practice what this means is that LDA will be less than optimal if the data\n",
    "don't meet our conditions.  That said, sometimes LDA works pretty well so we'll try it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize the LDA model\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "\n",
    "# Fit the model to the training data\n",
    "lda.fit(X_scaled, y)\n",
    "\n",
    "# Now that we have transformed the data, let's use LDA to make predictions on the test data\n",
    "\n",
    "y_pred = lda.predict(X_scaled)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that some of the measures for classification prefer values that are numeric in outcomes rather than categorical as we have here, so we'll have a second set of values for y and predicted y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred2= (y_pred == \"M\").astype(int)\n",
    "y2=(y==\"M\").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the specificity \n",
    "def specificity_score(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate specificity.\n",
    "\n",
    "    Args:\n",
    "        y_true (list or numpy.ndarray): True labels.\n",
    "        y_pred (list or numpy.ndarray): Predicted labels.\n",
    "\n",
    "    Returns:\n",
    "        float: Specificity score.\n",
    "    \"\"\"\n",
    "    true_negatives = sum((y_true == 0) & (y_pred == 0))\n",
    "    false_positives = sum((y_true == 0) & (y_pred == 1))\n",
    "    \n",
    "    if (true_negatives + false_positives) == 0:\n",
    "      return 0.0\n",
    "    \n",
    "    specificity = true_negatives / (true_negatives + false_positives)\n",
    "    return specificity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is to evaluate the performance of our metrics.  These are below.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain and print classification performance for LDA\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "print(cm)\n",
    "\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "precision = precision_score(y2, y_pred2)\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "\n",
    "recall = recall_score(y2, y_pred2)\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "\n",
    "specificity = specificity_score(y2, y_pred2)\n",
    "print(f\"specificity: {recall:.4f}\")\n",
    "\n",
    "f1 = f1_score(y2, y_pred2)\n",
    "print(f\"f1: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this output we can see that (76+6) = 82 of the tumors were not predicted accurately but we still got an overall accuracy of $0.8559$.  _Precision_ was good but _recall_ was not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### F1 score\n",
    "Above we used a new metric for assessing our classification performance, f1.\n",
    "\n",
    "[<https://developers.google.com/machine-learning/crash-course/classification/accuracy-precision-recall>]\n",
    "The F1 score is the harmonic mean (a kind of average) of precision and recall.\n",
    "\n",
    "Mathematically, it is given by:\n",
    "$$  \\text{F1}=2*\\frac{\\text{precision * recall}}{\\text{precision + recall}} = \\frac{2\\text{TP}}{2\\text{TP + FP + FN}}  $$\n",
    "\n",
    "This metric balances the importance of precision and recall, and is preferable to accuracy for class-imbalanced datasets. When precision and recall both have perfect scores of 1.0, F1 will also have a perfect score of 1.0. More broadly, when precision and recall are close in value, F1 will be close to their value. When precision and recall are far apart, F1 will be similar to whichever metric is worse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QDA\n",
    "\n",
    "Next we will look at quadratic discriminant analysis (QDA).  While QDA still uses a Normal distribution/density\n",
    "calculation for the decision rule, it is more robust and more flexible than LDA.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize the LDA model\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "\n",
    "# Fit the model to the training data\n",
    "qda.fit(X, y)\n",
    "\n",
    "# Now that we have transformed the data, let's use LDA to make predictions on the test data\n",
    "\n",
    "y_pred = qda.predict(X)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predicted values for QDA\n",
    "y_pred2= (y_pred == \"M\").astype(int)\n",
    "y2=(y==\"M\").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain and print classification performance for QDA\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "print(cm)\n",
    "\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "precision = precision_score(y2, y_pred2)\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "\n",
    "recall = recall_score(y2, y_pred2)\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "\n",
    "specificity = specificity_score(y2, y_pred2)\n",
    "print(f\"specificity: {recall:.4f}\")\n",
    "\n",
    "f1 = f1_score(y2, y_pred2)\n",
    "print(f\"f1: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So from the confusion matrix we can see that now 68 = 58+10 of the tumors were non correctly predicted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN\n",
    "The next methodology that we'll consider is _k_ Nearest Neighbors (kNN).  The idea behind kNN is to take\n",
    "the observations that are closest to each point and have those points vote for what should be the predicted value\n",
    "of that observation.  Generally, odd numbers of _k_ are chosen so there are no ties.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate and fit the model\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the predicted values\n",
    "knn_preds_3 = knn.predict(X_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making predicted values for kNN with k=3\n",
    "y_pred2= (knn_preds_3 == \"M\").astype(int)\n",
    "y_pred=knn_preds_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performance for kNN with k=3\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "print(cm)\n",
    "\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "precision = precision_score(y2, y_pred2)\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "\n",
    "recall = recall_score(y2, y_pred2)\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "\n",
    "specificity = specificity_score(y2, y_pred2)\n",
    "print(f\"specificity: {recall:.4f}\")\n",
    "\n",
    "f1 = f1_score(y2, y_pred2)\n",
    "print(f\"f1: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With 48 observations here that are predicted inaccurately, this model is better than either LDA or QDA.  \n",
    "\n",
    "One choice that has to be made when using kNN is the choice of how many observations will be included as 'neighbors' that are 'nearest'.  So let's try another value for _k_ , say, _k_=7.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn7 = KNeighborsClassifier(n_neighbors=7)\n",
    "knn7.fit(X_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_preds_7 = knn7.predict(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making predicted values for kNN with k=7\n",
    "y_pred2= (knn_preds_7 == \"M\").astype(int)\n",
    "y_pred=knn_preds_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performance for kNN with k=7\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "print(cm)\n",
    "\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "precision = precision_score(y2, y_pred2)\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "\n",
    "recall = recall_score(y2, y_pred2)\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "\n",
    "specificity = specificity_score(y2, y_pred2)\n",
    "print(f\"specificity: {recall:.4f}\")\n",
    "\n",
    "f1 = f1_score(y2, y_pred2)\n",
    "print(f\"f1: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn25 = KNeighborsClassifier(n_neighbors=25)\n",
    "knn25.fit(X_scaled, y)\n",
    "knn_preds_25 = knn25.predict(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making predicted values for kNN with k=25\n",
    "y_pred2= (knn_preds_25 == \"M\").astype(int)\n",
    "y_pred=knn_preds_25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performance for kNN with k=25\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "print(cm)\n",
    "\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "precision = precision_score(y2, y_pred2)\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "\n",
    "recall = recall_score(y2, y_pred2)\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "\n",
    "f1 = f1_score(y2, y_pred2)\n",
    "print(f\"f1: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks\n",
    "\n",
    "1. Write a loop to compare the accuracy of kNN when k=3,5,7,...,19, store the accuracies that you get and plot the resulting accuracies.  Determine which value for _k_ give the best prediction.\n",
    "\n",
    "2. Add radius and texture as features to the _X_ matrix.  Compare LDA, QDA and kNN with these features added.  Was adding these features useful?\n",
    "\n",
    "3. What visualizations that we used in DTSC 2302 might be useful for determining if a predictor is useful?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_values=[3,5,7,9,11,13,15,19]\n",
    "accuracy_k = []\n",
    "# loop through taking a sample and calculating a mean from the sample n_reps times\n",
    "for i in k_values:\n",
    "  knn = KNeighborsClassifier(n_neighbors=i)\n",
    "  knn.fit(X_scaled, y)\n",
    "  knn_preds = knn.predict(X_scaled)\n",
    "  accuracy_k.append(accuracy_score(y, knn_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(k_values,accuracy_k)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=bcancer[['Concavity','Texture','Radius','Area']]\n",
    "y=bcancer['Diagnosis']\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X_scaled, y)\n",
    "y_pred = lda.predict(X_scaled)\n",
    "\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "print(cm)\n",
    "\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "precision = precision_score(y2, y_pred2)\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "\n",
    "recall = recall_score(y2, y_pred2)\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "\n",
    "f1 = f1_score(y2, y_pred2)\n",
    "print(f\"f1: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qda = QuadraticDiscriminantAnalysis()\n",
    "qda.fit(X_scaled, y)\n",
    "y_pred = qda.predict(X_scaled)\n",
    "y_pred2= (y_pred == \"M\").astype(int)\n",
    "\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "print(cm)\n",
    "\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "precision = precision_score(y2, y_pred2)\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "\n",
    "recall = recall_score(y2, y_pred2)\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "\n",
    "f1 = f1_score(y2, y_pred2)\n",
    "print(f\"f1: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn25 = KNeighborsClassifier(n_neighbors=5)\n",
    "knn25.fit(X_scaled, y)\n",
    "y_pred = knn25.predict(X_scaled)\n",
    "y_pred2= (y_pred == \"M\").astype(int)\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "print(cm)\n",
    "\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "precision = precision_score(y2, y_pred2)\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "\n",
    "recall = recall_score(y2, y_pred2)\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "\n",
    "f1 = f1_score(y2, y_pred2)\n",
    "print(f\"f1: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=\"Diagnosis\", y=\"Compactness\",data=bcancer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=\"Diagnosis\", y= \"Area\",data=bcancer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=\"Diagnosis\", y= \"Smoothness\",data=bcancer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification with more than two classes\n",
    "\n",
    "In the next section we are going to look at classification with more than two classes.  We'll start with the _iris_ data.\n",
    "\n",
    "And we'll add some cross validation.\n",
    "\n",
    "Additionally, when we are dealing with multi-class, more than 2 classes, classification we usually focus on the accuracy of the model and less on the other metrics.\n",
    "\n",
    "Also note that logistic regression cannot be used for multi-class classification though there is an extension called multinomial logistic regression that is specifically for prediction of multiple categories.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "# need to add 'load_iris'\n",
    "from sklearn.datasets import load_iris\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "feature_names = iris.feature_names\n",
    "target_names = iris.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will split the data here with 30% of the data going into the test set (*test_size=0.3*).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=250325)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing the data for better performance of kNN (kNN is sensitive to feature scaling)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining and training the classifiers\n",
    "\n",
    "# note that LDA and QDA inherently scale their features/predictors\n",
    "# so technically we could use lda.fit(X_train,y_train) and get the same results here\n",
    "# but for consistencly we'll still with \n",
    "\n",
    "## 1. Linear Discriminant Analysis (LDA)\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X_train_scaled, y_train)\n",
    "\n",
    "## 2. Quadratic Discriminant Analysis (QDA)\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "qda.fit(X_train_scaled, y_train)\n",
    "\n",
    "## 3. k-Nearest Neighbors (kNN)\n",
    "knn3 = KNeighborsClassifier(n_neighbors=3)\n",
    "knn3.fit(X_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions with each classifier\n",
    "lda_preds = lda.predict(X_test_scaled)\n",
    "qda_preds = qda.predict(X_test_scaled)\n",
    "knn_preds = knn3.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Performance of {model.__class__.__name__}:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the evaluation method for the \n",
    "evaluate_model(lda, X_test_scaled, y_test)\n",
    "print(\"\")\n",
    "evaluate_model(qda,X_test_scaled,y_test)\n",
    "print(\"\")\n",
    "evaluate_model(knn3,X_test_scaled,y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the out of sample accuracy of the models is the same for this particular choice of the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing confusion matrices for each classifier\n",
    "# Here's another function for plotting the confusion matrix\n",
    "def plot_confusion_matrix(y_true, y_pred, title='Confusion Matrix'):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=target_names, yticklabels=target_names)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting confusion matrices\n",
    "plot_confusion_matrix(y_test, lda_preds, 'LDA Confusion Matrix')\n",
    "plot_confusion_matrix(y_test, qda_preds, 'QDA Confusion Matrix')\n",
    "plot_confusion_matrix(y_test, knn_preds, 'kNN Confusion Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks\n",
    "\n",
    "4. For the above data, change the _k_ in the kNN from 3 to 9.  How does the performance change?\n",
    "\n",
    "5. What if we changed the test and train set, should we expect the same results?  Change the 'random_state' to a different value and rerun these analyses.  Do you get the same results?  \n",
    "\n",
    "6. Open the Penguins dataset, we now want to predict Penguin species using body mass, flipper length and bill length.  Run an analysis like we did above for the _iris data_ on the penguin data.  Evaluate the \n",
    "\n",
    "7. Continuing with the Penguins dataset, using the predictors from the previous task compare the out-of-sample performance of different values for _k_ in the kNN approach with these data.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn9 = KNeighborsClassifier(n_neighbors=9)\n",
    "knn9.fit(X_train_scaled, y_train)\n",
    "evaluate_model(knn9,X_test_scaled,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "# Standardizing the data for better performance of kNN (kNN is sensitive to feature scaling)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins = pd.read_csv(\"https://webpages.charlotte.edu/mschuck1/classes/DTSC2301/Data/penguins.csv\", na_values=['NA'])\n",
    "# remove rows with missing data\n",
    "penguins.dropna(inplace=True)\n",
    "penguins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=penguins[['body_mass_g', 'flipper_length_mm', 'bill_length_mm']]\n",
    "y=penguins['species']\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=250326)\n",
    "\n",
    "# Standardizing the data for better performance of kNN (kNN is sensitive to feature scaling)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "feature_names = ['body_mass_g', 'flipper_length_mm', 'bill_length_mm']\n",
    "target_names = ['Adelie', 'Gentoo', 'Chinstrap']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## 1. Linear Discriminant Analysis (LDA)\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X_train_scaled, y_train)\n",
    "\n",
    "## 2. Quadratic Discriminant Analysis (QDA)\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "qda.fit(X_train_scaled, y_train)\n",
    "\n",
    "## 3. k-Nearest Neighbors (kNN)\n",
    "knn3 = KNeighborsClassifier(n_neighbors=3)\n",
    "knn3.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Making predictions with each classifier\n",
    "lda_preds = lda.predict(X_test_scaled)\n",
    "qda_preds = qda.predict(X_test_scaled)\n",
    "knn_preds = knn3.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the evaluation method for the \n",
    "evaluate_model(lda, X_test_scaled, y_test)\n",
    "print(\"\")\n",
    "evaluate_model(qda,X_test_scaled,y_test)\n",
    "print(\"\")\n",
    "evaluate_model(knn3,X_test_scaled,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting confusion matrices\n",
    "plot_confusion_matrix(y_test, lda_preds, 'LDA Confusion Matrix')\n",
    "plot_confusion_matrix(y_test, qda_preds, 'QDA Confusion Matrix')\n",
    "plot_confusion_matrix(y_test, knn_preds, 'kNN Confusion Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_values=[3,5,7,9,11,13,15,19, 21, 23, 25]\n",
    "accuracy_k = []\n",
    "# loop through taking a sample and calculating a mean from the sample n_reps times\n",
    "for i in k_values:\n",
    "  knn = KNeighborsClassifier(n_neighbors=i)\n",
    "  knn.fit(X_train_scaled, y_train)\n",
    "  knn_preds = knn.predict(X_test_scaled)\n",
    "  accuracy_k.append(accuracy_score(y_test, knn_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(k_values,accuracy_k)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
